\section{Phương pháp nghiên cứu}
\subsection{Linear Regression}
Hồi quy tuyến tính là một kỹ thuật thống kê được sử dụng để mô hình hóa mối liên hệ giữa một biến phụ thuộc và một hoặc nhiều biến độc lập. Phương pháp này giả định một mối quan hệ tuyến tính và cố gắng xác định đường thẳng tối ưu nhằm giảm thiểu sự chênh lệch giữa các giá trị dự đoán và quan sát được. Hồi quy tuyến tính được áp dụng để dự đoán kết quả và hiểu về ảnh hưởng của các biến trong các lĩnh vực như kinh tế, tài chính và học máy. Phương pháp này, được giới thiệu bởi nhà thống kê nổi tiếng Sir Francis Galton vào cuối thế kỷ 19, nhằm xác định một phương trình tuyến tính đại diện cho mối quan hệ. Công thức cho hồi quy tuyến tính thường được biểu diễn dưới dạng một phương trình mô tả đường thẳng tối ưu này được biết đến là:
\[y=\beta_0+\beta_1x+\varepsilon\]
Trong đó:\\
	\indent\textbullet\ \(y\) là giá trị dự đoán của biến phụ thuộc (y).\\
	\indent\textbullet\ \(x\) là các biến độc lập.\\
	\indent\textbullet\ \(\beta_0\) là giá trị dự đoán của y khi X bằng 0 (intercept).\\
	\indent\textbullet\ \(\beta_1\) là hệ số hồi quy – cho biết giá trị dự đoán y thay đổi như thế nào khi X thay đổi.\\
	\indent\textbullet\ \(\varepsilon\) là sai số.\\
\\
Công thức tính \(\beta_0\) và \(\beta_1\):\\
\[\beta_1=\frac{\sum\left(x_i-\bar{x}\right)\left(y_i-\bar{y}\right)}{\sum\left(x_i-\bar{x}\right)^2}\]
\[\beta_0=\bar{y}-\beta_1\bar{x}\]
Trong đó:\\
	\indent\textbullet\ \(x_i\) và \(y_i\) là các giá trị cụ thể của biến độc lập và phụ thuộc.\\
	\indent\textbullet\ \(\bar{x}\) và \(\bar{y}\) là giá trị trung bình của \(x\) và \(y\) tương ứng.\\
\\
Công thức tính \(R^2\):
\[R^2=1-\frac{\sum\left(y_i-\hat{y_i}\right)^2}{\sum\left(y_i-\bar{y}\right)^2}\]
Trong đó:\\
	\indent\textbullet\ \(\hat{y_i}\) là giá trị dự đoán của \(y_i\)\\
	\indent\textbullet\ \(\bar{y_i}\) là giá trị trung bình của \(y\)\\

% =========================================
\subsection{ARIMA}
Autoregressive Integrated Moving Average (ARIMA) là thuật toán thống kê phổ biến dùng để dự báo dữ liệu chuỗi thời gian, được kết hợp giữa Tự hồi quy (Autogressive - AR), Trung bình trượt (Moving Average – MA) và tích hợp sai phân (Integrated – I).
\par
Tự hồi quy (AR) là mô hình tìm mối quan hệ giữa giá trị dữ liệu hiện tài và giá trị dữ liệu trước đó, còn được gọi là độ trễ. Mô hình có phương trình như sau:
\[y_{t} = c + \ \phi_{1}y_{t - 1} + \ \phi_{2}y_{t - 2} + \ldots + \ \phi_{p}y_{t - p} + \ \varepsilon_{t}\]
Trong đó:\\
    \indent\textbullet\ \(y_{t}\) là quan sát tại thời điểm t\\
    \indent\textbullet\ \(c\) là hệ số chặn\\
    \indent\textbullet\ \(\phi_{1},\ \ldots\ ,\ \phi_{p}\) là các tham số cần ước tính\\
    \indent\textbullet\ \(y_{t - 1},\ ...,\ y_{t - p}\) là các giá trị dự báo tại p bước thời điểm trước đó\\
    \indent\textbullet\ \(\varepsilon_{t}\) là nhiễu trắng\\

Sai phân (Integrated – I) là biểu thị sự khác biệt của các quan sát để làm cho chuỗi thời gian có tính dừng, nghĩa là các giá trị dữ liệu được thay thế bằng hiệu giữa giá trị dữ liệu hiện tại và trước đó.
\[y_{t} = \ Y_{t} - \ Y_{t - d}\]
Trong đó:\\
    \indent\textbullet\ \(y_{t}\) là sai phân tại thời điểm t\\
    \indent\textbullet\ \(Y_{t},\ \ldots,\ Y_{t - d}\) là các quan sát tại thời điểm hiện tại và trước đó\\

Trung bình trượt (MA) là mô hình thay vì sử dụng các quan sát trong quá khứ của các biến dự báo hồi quy, trung bình trượt sử dụng các lỗi dữ báo trong quá khứ.
\[y_{t} = c + \ \theta_{1}\varepsilon_{t - 1} + \ \theta_{2}\varepsilon_{t - 2} + \ldots + \ \theta_{q}\varepsilon_{t - q} + \ \varepsilon_{t}\]
Trong đó:\\
    \indent\textbullet\ \(y_{t}\) là trung bình trượt tại thời điểm t\\
    \indent\textbullet\ \(c\) là hệ số chặn\\
    \indent\textbullet\ \(\theta_{1},\ \ldots\ ,\ \theta_{p}\) là các tham số cần ước tính\\
    \indent\textbullet\ \(\varepsilon_{t - 1},\ \ldots,\ \varepsilon_{t - p}\) là các lỗi dữ báo tại q bước thời điểm trước đó\\
    \indent\textbullet\ \(\varepsilon_{t}\) là nhiễu trắng\\

Kết hợp cả ba mô hình trên thì có thể đưa ra phương trình cho mô hình ARIMA như sau:
\[y_{t} = c + \ \phi_{1}y_{t - 1} + \ldots + \ \phi_{p}y_{t - p} + \ \theta_{1}\varepsilon_{t - 1} + \ldots + \ \theta_{q}\varepsilon_{t - q} + \ \varepsilon_{t}\]
Trong đó:\\
    \indent\textbullet\ \(y_{t}\) là quan sát tại thời điểm t\\
    \indent\textbullet\ \(c\) là giá trị hằng\\
    \indent\textbullet\ \(\phi_{p}\) là tham số của AR\\
    \indent\textbullet\ \(\theta_{q}\) là tham số của MA\\
    \indent\textbullet\ \(\varepsilon_{t}\) là nhiễu trắng\\

Các giá trị tham số của mô hình ARIMA (p, d, q), AR(p) có thể được tính bằng Hàm tự tương quan (Autocorrelation Function – ACF), I(d) có thể sử dụng các loại kiểm định như Dickey Fuller (DF) hoặc Augmented Dickey Fuller (ADF) nếu như chuỗi thời gian chưa dừng và MA(q) có thể sử dụng Hàm tự tương quan một phần (Partial Autocorrelation Function PACF). Những hàm này giúp tính toán các tham số mà có thể được sử dụng trong dự báo dữ liệu trong mô hình ARIMA.

% =========================================
\subsection{RNN}
Nội dung. 

% =========================================
\subsection{LSTM}
Mạng bộ nhớ dài-ngắn (Long Short Term Memory networks), thường được gọi là LSTM - là một dạng đặc biệt của RNN, nó có khả năng học được các phụ thuộc xa. LSTM được giới thiệu bởi Hochreiter \& Schmidhuber (1997), và sau đó đã được cải tiến và phổ biến bởi rất nhiều người trong ngành. Chúng hoạt động cực kì hiệu quả trên nhiều bài toán khác nhau nên dần đã trở nên phổ biến như hiện nay.
\par
LSTM là một mạng nơ-ron tuần tự sâu trong học sâu, cho phép thông tin tồn tại lâu dài.
\par
Đây là một loại đặc biệt của Mạng Nơ-ron Tái Phát, có khả năng xử lý vấn đề vanishing gradient gặp phải bởi RNN.
    \indent\textbullet\ Output: \(c\), \(htct\), \(ht\). Ở đây, \(c\) biểu diễn trạng thái của ô (cell state) và \(h\) biểu diễn trạng thái ẩn (hidden state).
    \indent\textbullet\ Input: \(ct\)-1, \(ht\)-1\(ht\)-1, \(ht\)-1. Trong đó, \(xtxt\) là đầu vào tại trạng thái thứ \(t\) của mô hình. \(ct\)-1, \(ht\)-1\(ht\)-1, \(ht\)-1 là đầu ra từ lớp trước. \(h\) chơi vai trò tương tự như \(s\) trong RNN, trong khi \(c\) là điểm mới của LSTM.

\begin{minipage}{0.5\textwidth}
\centering
\includegraphics[width=1\textwidth]{resources/chapter-4/lstm-1.png}
\end{minipage}

Kí hiệu \(\sigma\), \(\tanh\) có nghĩa là dùng sigma, tanh và activation function
\par
\( f_t \), \( i_t \), \( o_t \) tương ứng với forget gate, input gate và output gate.\\
    \indent\textbullet\ Forget gate: \( f_t = \sigma\left(U_f \ast x_t + W_f \ast h_{t-1} + b_f\right) \)\\
    \indent\textbullet\ Input gate: \( i_t = \sigma\left(U_i \ast x_t + W_i \ast h_{t-1} + b_i\right) \)\\
    \indent\textbullet\ Output gate: \( o_t = \sigma\left(U_o \ast x_t + W_o \ast h_{t-1} + b_o\right) \)
\par
Nhận xét: \( 0 < f_t, i_t, o_t < 1 \); \( b_f, b_i, b_o \) là các hệ số bias.
\par
\( c_t = \tanh\left(U_c \ast x_t + W_c \ast h_{t-1} + b_c\right) \).
\par
\( c_t = f_t \ast c_{t-1} + i_t \ast c_t \), forget gate quyết định xem cần lấy bao nhiêu từ cell state trước và input gate sẽ quyết định lấy bao nhiêu từ input của state và hidden layer của layer trước.
\par
\( h_t = o_t \ast \tanh\left(c_t\right) \), output gate quyết định xem cần lấy bao nhiêu từ cell state để trở thành output của hidden state. Ngoài ra \( h_t \) cũng được dùng để tính ra output \( y_t \) cho state \( t \).


% =========================================
\subsection{GRU}
Nội dung.

% =========================================
\subsection{VARMA}
Vector Autoregressive Moving Average (VARMA) là mô hình thống kê dùng để mô hình hóa và dự đoán chuỗi dữ liệu có nhiều biến . VARMA là sự kết hợp giữa hai mô hình: Vector tự hồi quy (VAR) là mô hình dùng để kiểm tra các mối quan hệ giữa các biến tương tác với nhau. Trung bình trượt (MA) là mô hình thay vì sử dụng các quan sát trong quá khứ của các biến dự báo hồi quy, trung bình trượt sử dụng các lỗi dữ báo trong quá khứ. 
\par
Khi kết hợp hai mô hình lại thì mô hình VARMA được định nghĩa như sau:
\[y_{t} = c + \ \phi_{1}y_{t - 1} + \ldots + \ \phi_{p}y_{t - p} + CD_{t} + \ \theta_{1}\varepsilon_{t - 1} + \ldots + \ \theta_{q}\varepsilon_{t - p} + \ \varepsilon_{t}\]
Trong đó:\\
    \indent\textbullet\ \(y_{t}\) là vector của các biến chuỗi thời gian tại thời điểm t\\
    \indent\textbullet\ \(c\) là vector độ lệch không đổi trong mỗi phương trình\\
    \indent\textbullet\ \(\phi_{1},\ \ldots\ ,\ \phi_{p}\) là ma trận tham số của AR với i = 1, …, p\\
    \indent\textbullet\ \(C\) là ma trận hệ số của các biến hồi quy có khả năng xác định\\
    \indent\textbullet\ \(D_{t}\) là vector chứa các biến hồi quy xác định thích hợp như biến không đổi, xu hướng hoặc mùa vụ\\
    \indent\textbullet\ \(\theta_{1},\ \ldots\ ,\ \theta_{p}\) là ma trận tham số của MA với j = 1, … , q\\
    \indent\textbullet\ \(\varepsilon_{t}\) là vector lỗi ngẫu nhiêu tại thời điểm t\\

% =========================================
\subsection{Kalman Filter}
Nội dung.

% =========================================
\subsection{Meta-learning}
Meta-learning là một phương pháp trong học máy nhằm huấn luyện các mô hình để học một cách hiệu quả các nhiệm vụ mới với lượng dữ liệu hạn chế. Một trong những thuật toán nổi tiếng nhất trong meta-learning là Model-Agnostic Meta-Learning (MAML).
\par
\textbf{Model-Agnostic Meta-Learning (MAML)}
\par
Mục tiêu: MAML nhằm tìm một khởi tạo tốt cho các tham số của mô hình, giúp mô hình có thể được tinh chỉnh nhanh chóng trên một nhiệm vụ mới chỉ với một vài bước cập nhật gradient.
\par
\textbf{Khái niệm chính}
\par
    \indent\textbullet\ 1.	Phân phối nhiệm vụ (p(T)p(T)): Một phân phối trên các nhiệm vụ mà mô hình cần thích nghi.\\
    \indent\textbullet\ 2.	Mô hình cơ bản (\(f_\theta f_\theta\)): Mô hình được tham số hóa bởi \(\theta \theta\).\\
    \indent\textbullet\ 3.	Bộ dữ liệu hỗ trợ (Support Set): Bộ dữ liệu nhỏ từ đó mô hình học nhiệm vụ.\\
    \indent\textbullet\ 4.	Bộ dữ liệu truy vấn (Query Set): Bộ dữ liệu được dùng để đánh giá mô hình sau khi nó đã thích nghi với nhiệm vụ.\\
\par
\textbf{Các bước của thuật toán MAML}
\par
    \indent\textbullet\ 1.	Khởi tạo tham số mô hình: Bắt đầu với các tham số khởi tạo \(\theta \theta\).\\
    \indent\textbullet\ 2.	Lấy mẫu một loạt các nhiệm vụ: Lấy mẫu một loạt các nhiệm vụ {Ti}{Ti} từ phân phối nhiệm vụ p(T)p(T)\\
    \indent\textbullet\ 3. Đối với mỗi nhiệm vụ \(T_i\)\\
    	Lấy mẫu bộ dữ liệu hỗ trợ \(D_{T_i}^{\mathrm{train\ }}\) và bộ dữ liệu truy vấn \(D_{T_i}^{\mathrm{test\ }}\).\\ \\
     	Tính gradient của hàm mất mát trên bộ dữ liệu hỗ trợ với tham số \(\theta\):\\
            \[\nabla_\theta\mathcal{L}_{T_i}\left(f_\theta\right)\] \\
            Cập nhật các tham số sử dụng gradient:\\
            \[\theta_i^\prime=\theta-\alpha\nabla_\theta\mathcal{L}_{T_i}\left(f_\theta\right)\] \\
        \indent\textbullet\ 4. Cập nhật Meta\\
            Tính hàm mất mát trên bộ dữ liệu truy vấn sử dụng tham số đã cập nhật \(\theta_i^\prime\) \\ 
            \[\mathcal{L}_{T_i}\left(f_{\theta_i^\prime}\right)\]\\
            Tính gradient của hàm mất mát trên bộ dữ liệu truy vấn đối với các tham số khởi tạo \(\theta\) \\
            \[\nabla_\theta\mathcal{L}_{T_i}\left(f_{\theta_i^\prime}\right)\] \\
            Cập nhật các tham số khởi tạo \(\theta\) bằng cách trung bình các gradient qua loạt nhiệm vụ: \\
            \[\theta \gets \theta - \beta \sum_{i} \, \nabla_{\theta} \mathcal{L}_{T_{i}} \left( f_{\theta_{i}^{\prime}} \right)\]
            , với \(\beta\) là tốc độ học của meta.


% =========================================
\subsection{NBeats}
Nội dung.

% =========================================
\subsection{N-HiTS}
Nội dung.